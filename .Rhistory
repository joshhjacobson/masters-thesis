scale_y_continuous(breaks = (-2:2) * 30) +
scale_x_continuous(breaks = (-4:4) * 45) +
coord_map("ortho", orientation = c(41, -74, 0)) +
labs(x="", y="") +
theme(axis.line=element_blank(),axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank(),legend.position="none",
panel.background=element_blank(), panel.border=element_blank(),
panel.grid.major=element_line("grey"),
panel.grid.minor=element_line("grey"),
plot.background=element_blank())
library(rworldmap)
vignette('rworldmap')
?rnaturalearth
?ne_countries
ctrys50m <- ne_countries(scale = 50, type = "countries", returnclass = "sf")
View(ctrys50m)
joinCountryData2Map(ctrys50m)
joinData2Map(ctrys50m)
world <- map_data("world")
worldmap <- ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "white", colour = "black")
worldmap <- ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "white", colour = "black") +
coord_map("mercator")
ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "white", colour = "black") +
coord_map("mercator")
ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "white", colour = "black") +
coord_map("mercator") +
theme_light()
ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "grey", colour = "black") +
coord_map("lambert", parameters = c(-37, -44)) +
theme_light()
ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "grey", colour = "black") +
coord_map("lambert") +
theme_light()
ggplot() +
geom_polygon(data = world, aes(long, lat, group = group), fill = "grey", colour = "black") +
coord_map("stereographic") +
theme_light()
library(sp)
library(rworldmap) # this pkg has waaaay better world shapefiles
plot(spTransform(getMap(), CRS("+proj=wintri")))
install.packages("rgdal")
library(rdgal)
library(rgdal)
plot(spTransform(getMap(), CRS("+proj=wintri")))
plot(spTransform(getMap(), CRS("+proj=merc")))
plot(spTransform(getMap(), CRS("+proj=tmerc")))
library(ggplot2)
library(sf)
library(rnaturalearth)
library(dplyr)
crs <- "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +datum=WGS84 +units=m +no_defs"
ctrys50m <- ne_countries(scale = 50, type = "countries", returnclass = "sf") %>%
select(iso_a3, iso_n3, admin)
sphere <- st_graticule(ndiscr = 10000, margin = 10e-6) %>%
st_transform(crs = crs) %>%
st_convex_hull() %>%
summarise(geometry = st_union(geometry))
# need to figure out how to adjust viewpoint
ggplot()  +
geom_sf(data = sphere, fill = "#D8F4FF", alpha = 0.5) +
geom_sf(data = ctrys50m, fill="grey") +
theme_light()
# Test: Plot 3D globe with usa filled in
usa <-  map_data("usa")
world <- map_data("world")
ggplot() +
geom_polygon(data = world, aes(x = long, y = lat, group = group), fill='grey', colour='black') +
geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill='grey', colour='red') +
scale_y_continuous(breaks = (-2:2) * 30) +
scale_x_continuous(breaks = (-4:4) * 45) +
coord_map("ortho", orientation = c(41, -74, 0)) +
labs(x="", y="") +
theme(axis.line=element_blank(),axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank(),legend.position="none",
panel.background=element_blank(), panel.border=element_blank(),
panel.grid.major=element_line("grey"),
panel.grid.minor=element_line("grey"),
plot.background=element_blank())
library(ggplot2)
library(sf)
library(rnaturalearth)
library(dplyr)
crs <- "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +datum=WGS84 +units=m +no_defs"
ctrys50m <- ne_countries(scale = 50, type = "countries", returnclass = "sf") %>%
select(iso_a3, iso_n3, admin)
sphere <- st_graticule(ndiscr = 10000, margin = 10e-6) %>%
st_transform(crs = crs) %>%
st_convex_hull() %>%
summarise(geometry = st_union(geometry))
# need to figure out how to adjust viewpoint
ggplot()  +
geom_sf(data = sphere, fill = "#D8F4FF", alpha = 0.5) +
geom_sf(data = ctrys50m, fill="grey") +
theme_light()
# Test: Plot 3D globe with usa filled in
usa <-  map_data("usa")
world <- map_data("world")
ggplot() +
geom_polygon(data = world, aes(x = long, y = lat, group = group), fill='grey', colour='black') +
geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill='grey', colour='red') +
scale_y_continuous(breaks = (-2:2) * 30) +
scale_x_continuous(breaks = (-4:4) * 45) +
coord_map("ortho", orientation = c(41, -74, 0)) +
labs(x="", y="") +
theme(axis.line=element_blank(),axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank(),legend.position="none",
panel.background=element_blank(), panel.border=element_blank(),
panel.grid.major=element_line("grey"),
panel.grid.minor=element_line("grey"),
plot.background=element_blank())
# Use cartesian coordinates
usamap
# Prepare a map of NZ
nz <- map_data("nz")
nzmap <- ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
# Plot it in cartesian coordinates
nzmap
# With correct mercator projection
nzmap + coord_map()
# Other projections
nzmap + coord_map("cylindrical")
states <- map_data("state")
usamap <- ggplot(states, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
# Use cartesian coordinates
usamap
# With mercator projection
usamap + coord_map()
usamap + coord_quickmap()
# See ?mapproject for coordinate systems and their parameters
usamap + coord_map("gilbert")
usamap + coord_map("lagrange")
# For most projections, you'll need to set the orientation yourself
# as the automatic selection done by mapproject is not available to
# ggplot
usamap + coord_map("orthographic")
usamap + coord_map("stereographic")
usamap + coord_map("bonne", lat0 = 50)
# World map, using geom_path instead of geom_polygon
world <- map_data("world")
worldmap <- ggplot(world, aes(x = long, y = lat, group = group)) +
geom_path() +
scale_y_continuous(breaks = (-2:2) * 30) +
scale_x_continuous(breaks = (-4:4) * 45)
# Orthographic projection with default orientation (looking down at North pole)
worldmap + coord_map("ortho")
# Looking up up at South Pole
worldmap + coord_map("stereographic", orientation = c(90, 0, 0))
# Looking up up at South Pole
worldmap + coord_map("stereographic", orientation = c(90, 0))
# Looking up up at South Pole
worldmap + coord_map("stereographic", orientation = c(90, 0, 0))
# Test: Plot 3D globe with usa filled in
usa <-  map_data("usa")
world <- map_data("world")
ggplot() +
geom_polygon(data = world, aes(x = long, y = lat, group = group), fill='grey', colour='black') +
geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill='grey', colour='red') +
scale_y_continuous(breaks = (-2:2) * 30) +
scale_x_continuous(breaks = (-4:4) * 45) +
coord_map("ortho", orientation = c(41, -74, 0)) +
labs(x="", y="") +
theme(axis.line=element_blank(),axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank(),legend.position="none",
panel.background=element_blank(), panel.border=element_blank(),
panel.grid.major=element_line("grey"),
panel.grid.minor=element_line("grey"),
plot.background=element_blank())
library(tidyverse)
library(dplyr)
library(ggplot2)
library(RSQLite)
library(glmnet)
library(class)
library(e1071)
library(nnet)
library(splines)
library(gam)
## create db connection
# conn <- dbConnect(SQLite(), '/Users/joshjacobson/Desktop/stats/wildfire-data.sqlite')
## pull the fires table into RAM
# fires <- tbl(conn, "Fires") %>% collect()
# dbDisconnect(conn)
# glimpse(fires)
## fires data subset
fires_reduced <- read_csv("wildfire_data.csv") # subset of columns from kaggle dataset
names(fires_reduced)
## global avg. daily temp anomalies
climdat <- read.table(file = "TAVG_daily.txt", header = FALSE)
# add names from complete file (note: YEAR and DOY are changed for merging convenience)
colnames(climdat) <- c("DATE_NUMBER", "FIRE_YEAR", "MONTH", "DAY", "DISCOVERY_DOY", "ANOMALY")
climdat <- climdat[, c("FIRE_YEAR", "DISCOVERY_DOY", "ANOMALY")]
climdat <- mutate_all(climdat, function(x) as.numeric(as.character(x)))
climdat <- filter(climdat, between(FIRE_YEAR, 1992, 2015))
############################################################################
## Data Preparation
############################################################################
## colorado fires subset with temp anomaly
fires_co <- subset(fires_reduced, STATE=="CO" )
fires_co <- fires_co[complete.cases(fires_co),]
fires_co <- as.data.frame(fires_co)
fires_co <- merge(fires_co, climdat, by=c("FIRE_YEAR", "DISCOVERY_DOY"),
all.x = FALSE, all.y = FALSE)
fires_co <- fires_co[complete.cases(fires_co),]
## Regression / Regularization ---------------------------------------------
## remove identification columns
fires_pred <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE_CLASS, STATE))
## reformat
fires_pred <- mutate_all(fires_pred, function(x) as.numeric(as.character(x)))
fires_pred <- fires_pred %>% mutate(FIRE_CODE = as.numeric(as.factor(fires_co$FIRE_CODE)))
## check
sapply(fires_pred,class)
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_pred))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_pred <- fires_pred[sample, ]
test_pred <- fires_pred[-sample, ]
## Classification ----------------------------------------------------------
## collect relevant data as numeric (cause as factor)
fires_class <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE, FIRE_SIZE_CLASS, STATE))
## reformat
fires_class <- mutate_all(fires_class, function(x) as.numeric(as.character(x)))
fires_class <- fires_class %>%
mutate(STAT_CAUSE_CODE = as.factor(as.character(STAT_CAUSE_CODE)),
OWNER_CODE = as.factor(as.character(OWNER_CODE)),
FIRE_CODE = as.factor(fires_co$FIRE_CODE),
FIRE_SIZE_CLASS = as.factor(fires_co$FIRE_SIZE_CLASS))
## check
sapply(fires_class,class)
## reorder
col_names <- names(fires_class)[1:14]
fires_class <- fires_class[ ,c("FIRE_SIZE_CLASS", col_names)]
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_class))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_class <- fires_class[sample, ]
test_class <- fires_class[-sample, ]
library(tidyverse)
library(dplyr)
library(ggplot2)
library(RSQLite)
library(glmnet)
library(class)
library(e1071)
library(nnet)
library(splines)
library(gam)
## create db connection
# conn <- dbConnect(SQLite(), '/Users/joshjacobson/Desktop/stats/wildfire-data.sqlite')
## pull the fires table into RAM
# fires <- tbl(conn, "Fires") %>% collect()
# dbDisconnect(conn)
# glimpse(fires)
## fires data subset
fires_reduced <- read_csv("wildfire_data.csv") # subset of columns from kaggle dataset
names(fires_reduced)
## global avg. daily temp anomalies
climdat <- read.table(file = "TAVG_daily.txt", header = FALSE)
# add names from complete file (note: YEAR and DOY are changed for merging convenience)
colnames(climdat) <- c("DATE_NUMBER", "FIRE_YEAR", "MONTH", "DAY", "DISCOVERY_DOY", "ANOMALY")
climdat <- climdat[, c("FIRE_YEAR", "DISCOVERY_DOY", "ANOMALY")]
climdat <- mutate_all(climdat, function(x) as.numeric(as.character(x)))
climdat <- filter(climdat, between(FIRE_YEAR, 1992, 2015))
############################################################################
## Data Preparation
############################################################################
## colorado fires subset with temp anomaly
fires_co <- subset(fires_reduced, STATE=="CO" )
fires_co <- fires_co[complete.cases(fires_co),]
fires_co <- as.data.frame(fires_co)
fires_co <- merge(fires_co, climdat, by=c("FIRE_YEAR", "DISCOVERY_DOY"),
all.x = FALSE, all.y = FALSE)
fires_co <- fires_co[complete.cases(fires_co),]
## Regression / Regularization ---------------------------------------------
## remove identification columns
fires_pred <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE_CLASS, STATE))
## reformat
fires_pred <- mutate_all(fires_pred, function(x) as.numeric(as.character(x)))
fires_pred <- fires_pred %>% mutate(FIRE_CODE = as.numeric(as.factor(fires_co$FIRE_CODE)))
## check
sapply(fires_pred,class)
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_pred))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_pred <- fires_pred[sample, ]
test_pred <- fires_pred[-sample, ]
## Classification ----------------------------------------------------------
## collect relevant data as numeric (cause as factor)
fires_class <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE, FIRE_SIZE_CLASS, STATE))
## reformat
fires_class <- mutate_all(fires_class, function(x) as.numeric(as.character(x)))
fires_class <- fires_class %>%
mutate(STAT_CAUSE_CODE = as.factor(as.character(STAT_CAUSE_CODE)),
OWNER_CODE = as.factor(as.character(OWNER_CODE)),
FIRE_CODE = as.factor(fires_co$FIRE_CODE),
FIRE_SIZE_CLASS = as.factor(fires_co$FIRE_SIZE_CLASS))
## check
sapply(fires_class,class)
## reorder
col_names <- names(fires_class)[1:14]
fires_class <- fires_class[ ,c("FIRE_SIZE_CLASS", col_names)]
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_class))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_class <- fires_class[sample, ]
test_class <- fires_class[-sample, ]
library(tidyverse)
library(dplyr)
library(ggplot2)
library(RSQLite)
library(glmnet)
library(class)
library(e1071)
library(nnet)
library(splines)
library(gam)
## create db connection
# conn <- dbConnect(SQLite(), '/Users/joshjacobson/Desktop/stats/wildfire-data.sqlite')
## pull the fires table into RAM
# fires <- tbl(conn, "Fires") %>% collect()
# dbDisconnect(conn)
# glimpse(fires)
## fires data subset
fires_reduced <- read_csv("wildfire_data.csv") # subset of columns from kaggle dataset
names(fires_reduced)
## global avg. daily temp anomalies
climdat <- read.table(file = "TAVG_daily.txt", header = FALSE)
# add names from complete file (note: YEAR and DOY are changed for merging convenience)
colnames(climdat) <- c("DATE_NUMBER", "FIRE_YEAR", "MONTH", "DAY", "DISCOVERY_DOY", "ANOMALY")
climdat <- climdat[, c("FIRE_YEAR", "DISCOVERY_DOY", "ANOMALY")]
climdat <- mutate_all(climdat, function(x) as.numeric(as.character(x)))
climdat <- filter(climdat, between(FIRE_YEAR, 1992, 2015))
############################################################################
## Data Preparation
############################################################################
## colorado fires subset with temp anomaly
fires_co <- subset(fires_reduced, STATE=="CO" )
fires_co <- fires_co[complete.cases(fires_co),]
fires_co <- as.data.frame(fires_co)
fires_co <- merge(fires_co, climdat, by=c("FIRE_YEAR", "DISCOVERY_DOY"),
all.x = FALSE, all.y = FALSE)
fires_co <- fires_co[complete.cases(fires_co),]
## Regression / Regularization ---------------------------------------------
## remove identification columns
fires_pred <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE_CLASS, STATE))
## reformat
fires_pred <- mutate_all(fires_pred, function(x) as.numeric(as.character(x)))
fires_pred <- fires_pred %>% mutate(FIRE_CODE = as.numeric(as.factor(fires_co$FIRE_CODE)))
## check
sapply(fires_pred,class)
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_pred))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_pred <- fires_pred[sample, ]
test_pred <- fires_pred[-sample, ]
## Classification ----------------------------------------------------------
## collect relevant data as numeric (cause as factor)
fires_class <- subset(fires_co, select = -c(FOD_ID, FPA_ID, FIRE_NAME, FIRE_CODE,
FIRE_SIZE, FIRE_SIZE_CLASS, STATE))
## reformat
fires_class <- mutate_all(fires_class, function(x) as.numeric(as.character(x)))
fires_class <- fires_class %>%
mutate(STAT_CAUSE_CODE = as.factor(as.character(STAT_CAUSE_CODE)),
OWNER_CODE = as.factor(as.character(OWNER_CODE)),
FIRE_CODE = as.factor(fires_co$FIRE_CODE),
FIRE_SIZE_CLASS = as.factor(fires_co$FIRE_SIZE_CLASS))
## check
sapply(fires_class,class)
## reorder
col_names <- names(fires_class)[1:14]
fires_class <- fires_class[ ,c("FIRE_SIZE_CLASS", col_names)]
## build test / train sets
set.seed(2820)
smp_size <- floor(0.75 * nrow(fires_class))
sample <- sample(seq_len(nrow(fires_co)), size=smp_size)
train_class <- fires_class[sample, ]
test_class <- fires_class[-sample, ]
install.packages("RandomFields")
setwd("~/GitHub/random-fields")
library(RandomFields)
?RMbiwm
RFoptions(seed=0) ## *ANY* simulation will have the random seed 0; set
## RFoptions(seed=NA) to make them all random again
x <- y <- seq(-10, 10, 0.2)
model <- RMbiwm(nudiag=c(0.3, 2), nured=1, rhored=1, cdiag=c(1, 1.5),
s=c(1, 1, 2))
plot(model)
plot(RFsimulate(model, x, y))
mod <- RMbiwm(nu = c(1.5, 1.5, 1,5), s = c(1, 1, 1), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(1.5, 1.5, 1,5), s = c(2, 2, 2), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
mod <- RMbiwm(nu = c(1.5, 1.5, 1,5), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
mod <- RMbiwm(nu = c(1.5, 1.5, 1,5), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 1)
plot(mod)
model <- RMbiwm(nudiag=c(0.3, 2), nured=1, rhored=1, cdiag=c(1, 1.5),
s=c(1, 1, 2))
plot(model)
plot(RFsimulate(model, x, y))
mod <- RMbiwm(nu = c(1, 2, 1), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 1)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(1, 2, 1), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(1, 1, 1), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(1.5, 1, 1), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
mod <- RMbiwm(nu = c(2, 2, 2), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(3/2, 2, 2), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
mod <- RMbiwm(nu = c(3/2, 3/2, 3/2), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
## Test
x <- y <- seq(-100, 100, 0.2)
mod <- RMbiwm(nu = c(3/2, 3/2, 3/2), s = c(0.5, 0.5, 0.5), cdiag = c(1, 1),
rhored = 0.8)
plot(mod)
plot(RFsimulate(mod, x, y))
?RFsimulate
RMsimulate.more.examples
?RMsimulate.more.examples
??RMsimulate.more.examples
#############################################################
## ##
## Unconditional simulation ##
## ##
#############################################################
## first let us look at the list of implemented models
RFgetModelNames(type="positive definite", domain="single variable",
iso="isotropic")
## our choice is the exponential model;
## the model includes nugget effect and the mean:
model <- RMexp(var=5, scale=10) + # with variance 4 and scale 10
RMnugget(var=1) + # nugget
RMtrend(mean=0.5) # and mean
## define the locations:
from <- 0
to <- 20
x.seq <- seq(from, to, length=200)
y.seq <- seq(from, to, length=200)
simu <- RFsimulate(model, x=x.seq, y=y.seq)
plot(simu)
#############################################################
## ##
## Conditional simulation ##
## ##
#############################################################
# first we simulate some random values at a
# 100 random locations:
n <- 100
x <- runif(n=n, min=-1, max=1)
y <- runif(n=n, min=-1, max=1)
data <- RFsimulate(model = RMexp(), x=x, y=y, grid=FALSE)
plot(data)
# let simulate a field conditional on the above data
x.seq.cond <- y.seq.cond <- seq(-1.5, 1.5, length=n)
model <- RMexp()
cond <- RFsimulate(model, x=x.seq.cond, y=y.seq.cond, data=data)
plot(cond, data)
plot(cond, data)
plot(data)
plot(cond)
plot(data)
plot(cond)
plot(cond, data)
plot(data)
